{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f4d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sqlalchemy import text\n",
    "import json\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import shutil\n",
    "import os\n",
    "import re\n",
    "import psutil\n",
    "import time\n",
    "import stat\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d285b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "engine = create_engine('mysql+pymysql://root:aman1234@localhost:3306/employee_info')\n",
    "\n",
    "# Get all table names dynamically\n",
    "inspector = inspect(engine)\n",
    "table_names = inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16330632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading table: attendance\n",
      "Loading table: employee\n",
      "Loading table: location\n",
      "Loading table: project\n",
      "Loading table: teammember\n",
      "Loading table: timetracking\n"
     ]
    }
   ],
   "source": [
    "# Function to convert a row dict to structured text for any table\n",
    "def row_to_text(table_name, row):\n",
    "    # Format each column as \"ColumnName: value\"\n",
    "    lines = [f\"{col}: {row.get(col, 'N/A')}\" for col in row.keys()]\n",
    "    return f\"Table: {table_name}\\n\" + \"\\n\".join(lines) + \"\\n\"\n",
    "\n",
    "# Collect all rows from all tables as text\n",
    "all_texts = []\n",
    "for table in table_names:\n",
    "    print(f\"Loading table: {table}\")\n",
    "    df = pd.read_sql(f\"SELECT * FROM `{table}`\", engine)\n",
    "    # Convert each row to text\n",
    "    for _, row in df.iterrows():\n",
    "        all_texts.append(row_to_text(table, row))\n",
    "\n",
    "# Combine all texts into one large string\n",
    "combined_text = \"\\n\".join(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136556f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39ce0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAP-4\\AppData\\Local\\Temp\\ipykernel_11432\\3696919488.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Split into chunks for embedding\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_text(combined_text)\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Chroma DB path - currently in same folder\n",
    "chroma_db_path = \"./chroma_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa39db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset ChromaDB storage.\n",
    "def kill_processes_using_path(path):\n",
    "    for proc in psutil.process_iter(['pid', 'name', 'open_files']):\n",
    "        try:\n",
    "            files = proc.info['open_files']\n",
    "            if files:\n",
    "                for f in files:\n",
    "                    if path in f.path:\n",
    "                        print(f\" Killing process {proc.pid} using {f.path}\")\n",
    "                        proc.kill()\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied):\n",
    "            continue\n",
    "\n",
    "def onerror(func, path, exc_info):\n",
    "    # Handle read-only files by changing permissions and retrying\n",
    "    if not os.access(path, os.W_OK):\n",
    "        os.chmod(path, stat.S_IWUSR)\n",
    "        func(path)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "if os.path.exists(chroma_db_path):\n",
    "    kill_processes_using_path(chroma_db_path)\n",
    "    time.sleep(2)  # wait for processes to terminate\n",
    "    shutil.rmtree(chroma_db_path, onerror=onerror)\n",
    "    print(\"Deleted old ChromaDB storage.\")\n",
    "\n",
    "# Remove existing Chroma DB directory if exists\n",
    "# if os.path.exists(chroma_db_path):\n",
    "#     kill_processes_using_path(chroma_db_path)\n",
    "#     time.sleep(1)  # wait 1 second\n",
    "#     shutil.rmtree(chroma_db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0bb2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (2.10.6)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.1-cp313-cp313-win_amd64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (2.2.2)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.22.0-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached pypika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (1.71.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-5.1.0-cp313-cp313-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.23.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.29.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.4-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-1.1.0-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\lap-4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading chromadb-1.0.15-cp39-abi3-win_amd64.whl (19.5 MB)\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/19.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/19.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/19.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/19.5 MB 636.1 kB/s eta 0:00:30\n",
      "   - -------------------------------------- 0.8/19.5 MB 776.3 kB/s eta 0:00:25\n",
      "   -- ------------------------------------- 1.0/19.5 MB 884.5 kB/s eta 0:00:21\n",
      "   -- ------------------------------------- 1.3/19.5 MB 966.5 kB/s eta 0:00:19\n",
      "   -- ------------------------------------- 1.3/19.5 MB 966.5 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.6/19.5 MB 906.0 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 1.6/19.5 MB 906.0 kB/s eta 0:00:20\n",
      "   --- ------------------------------------ 1.8/19.5 MB 863.3 kB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 2.1/19.5 MB 893.1 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 2.4/19.5 MB 937.6 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.6/19.5 MB 959.7 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 2.6/19.5 MB 959.7 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 2.9/19.5 MB 923.0 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.9/19.5 MB 923.0 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 3.1/19.5 MB 888.6 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 3.4/19.5 MB 908.8 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 3.7/19.5 MB 940.4 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 3.9/19.5 MB 925.8 kB/s eta 0:00:17\n",
      "   -------- ------------------------------- 4.2/19.5 MB 946.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 4.5/19.5 MB 955.4 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 4.7/19.5 MB 970.4 kB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 5.0/19.5 MB 980.2 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 5.0/19.5 MB 980.2 kB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 5.2/19.5 MB 959.9 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 5.5/19.5 MB 964.2 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 5.8/19.5 MB 976.4 kB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 5.8/19.5 MB 976.4 kB/s eta 0:00:15\n",
      "   ------------ --------------------------- 6.3/19.5 MB 1.0 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 6.6/19.5 MB 1.0 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 6.8/19.5 MB 1.0 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 7.1/19.5 MB 1.0 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 7.1/19.5 MB 1.0 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 7.3/19.5 MB 1.0 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 7.6/19.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 7.9/19.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 7.9/19.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 8.1/19.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 8.4/19.5 MB 1.0 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 8.7/19.5 MB 1.0 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 8.9/19.5 MB 1.0 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 9.2/19.5 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 9.4/19.5 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 9.7/19.5 MB 1.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 10.2/19.5 MB 1.1 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 10.5/19.5 MB 1.1 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 10.7/19.5 MB 1.1 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 11.3/19.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 11.3/19.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 11.5/19.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 11.5/19.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 11.8/19.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 12.1/19.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 12.3/19.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 12.6/19.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 12.8/19.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 13.4/19.5 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------------------- ------------ 13.6/19.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 13.9/19.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 14.2/19.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 14.4/19.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 14.4/19.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 14.7/19.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 15.2/19.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 15.5/19.5 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 15.7/19.5 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 15.7/19.5 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 16.0/19.5 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 16.3/19.5 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 16.5/19.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 16.8/19.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 17.0/19.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 17.3/19.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 17.6/19.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 17.8/19.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 18.1/19.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 18.4/19.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 18.6/19.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.9/19.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.4/19.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.5/19.5 MB 1.2 MB/s eta 0:00:00\n",
      "Using cached bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Using cached kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "Using cached mmh3-5.1.0-cp313-cp313-win_amd64.whl (41 kB)\n",
      "Using cached onnxruntime-1.22.0-cp313-cp313-win_amd64.whl (12.7 MB)\n",
      "Using cached opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "Using cached opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Using cached posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Using cached pybase64-1.4.1-cp313-cp313-win_amd64.whl (36 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Using cached httptools-0.6.4-cp313-cp313-win_amd64.whl (87 kB)\n",
      "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached watchfiles-1.1.0-cp313-cp313-win_amd64.whl (292 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, zipp, websockets, shellingham, pyreadline3, pyproject_hooks, pybase64, opentelemetry-proto, oauthlib, mmh3, importlib-resources, httptools, bcrypt, backoff, watchfiles, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, importlib-metadata, humanfriendly, build, typer, opentelemetry-api, kubernetes, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "Successfully installed backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.2.10 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-33.1.0 mmh3-5.1.0 oauthlib-3.3.1 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 posthog-5.4.0 pybase64-1.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 shellingham-1.5.4 typer-0.16.0 watchfiles-1.1.0 websockets-15.0.1 zipp-3.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28223f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store from chunks\n",
    "vector_db = Chroma.from_texts(chunks, embedding=embedding_model, persist_directory=chroma_db_path)\n",
    "# vector_db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "276504e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Search Results:\n",
      "\n",
      "Result 1:\n",
      "Table: timetracking\n",
      "id: 19\n",
      "user_id: 1001\n",
      "emp_code: E1001\n",
      "date: 2025-05-16\n",
      "time_spent: 1.5\n",
      "remarks: Team retrospective\n",
      "status: Approved\n",
      "discipline: Software Development\n",
      "\n",
      "Table: timetracking\n",
      "id: 20\n",
      "user_id: 1001\n",
      "emp_code: E1001\n",
      "date: 2025-05-20\n",
      "time_spent: 7.0\n",
      "remarks: New module development\n",
      "status: Approved\n",
      "discipline: Software Development\n",
      "\n",
      "Result 2:\n",
      "Table: timetracking\n",
      "id: 49\n",
      "user_id: 1002\n",
      "emp_code: E1002\n",
      "date: 2025-05-20\n",
      "time_spent: 1.0\n",
      "remarks: Stakeholder meeting\n",
      "status: Approved\n",
      "discipline: Digital Marketing\n",
      "\n",
      "Table: timetracking\n",
      "id: 50\n",
      "user_id: 1002\n",
      "emp_code: E1002\n",
      "date: 2025-05-21\n",
      "time_spent: 8.0\n",
      "remarks: New ad creative development\n",
      "status: Approved\n",
      "discipline: Digital Marketing\n",
      "\n",
      "Result 3:\n",
      "Table: timetracking\n",
      "id: 23\n",
      "user_id: 1001\n",
      "emp_code: E1001\n",
      "date: 2025-05-23\n",
      "time_spent: 5.0\n",
      "remarks: Technical debt reduction\n",
      "status: Approved\n",
      "discipline: Software Development\n",
      "\n",
      "Table: timetracking\n",
      "id: 24\n",
      "user_id: 1001\n",
      "emp_code: E1001\n",
      "date: 2025-05-23\n",
      "time_spent: 3.0\n",
      "remarks: Knowledge sharing session\n",
      "status: Approved\n",
      "discipline: Software Development\n",
      "\n",
      "Result 4:\n",
      "Table: project\n",
      "id: 2\n",
      "name: Mobile App Redesign\n",
      "code: MAR202\n",
      "allotted_man_hours: 800.0\n",
      "start_date: 2023-02-01\n",
      "end_date: 2023-05-15\n",
      "\n",
      "Table: project\n",
      "id: 3\n",
      "name: ERP Implementation\n",
      "code: ERP303\n",
      "allotted_man_hours: 2500.0\n",
      "start_date: 2023-03-01\n",
      "end_date: 2023-12-31\n",
      "\n",
      "Table: project\n",
      "id: 4\n",
      "name: Marketing Campaign\n",
      "code: MC404\n",
      "allotted_man_hours: 500.0\n",
      "start_date: 2023-04-01\n",
      "end_date: 2023-06-30\n",
      "\n",
      "Result 5:\n",
      "Table: timetracking\n",
      "id: 4\n",
      "user_id: 1001\n",
      "emp_code: E1001\n",
      "date: 2025-05-02\n",
      "time_spent: 1.0\n",
      "remarks: Documentation updates\n",
      "status: Approved\n",
      "discipline: Software Development\n",
      "\n",
      "Table: timetracking\n",
      "id: 5\n",
      "user_id: 1001\n",
      "emp_code: E1001\n",
      "date: 2025-05-03\n",
      "time_spent: 4.0\n",
      "remarks: Bug fixes and testing\n",
      "status: Approved\n",
      "discipline: Software Development\n"
     ]
    }
   ],
   "source": [
    "# Function to search employees or any data\n",
    "def search_database(query, top_k=5):\n",
    "    retrieved_chunks = vector_db.similarity_search(query, k=top_k)\n",
    "    return [chunk.page_content for chunk in retrieved_chunks]\n",
    "\n",
    "# Example search query\n",
    "query = \"what is the status of name AU203 project\"\n",
    "results = search_database(query)\n",
    "\n",
    "print(\"\\n🔍 Search Results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3932199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Groq Chat LLM\n",
    "os.environ[\"GROQ_API_KEY\"] = \"insert groq api key\"\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dde03d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖  AI Response: There are **<count>** active employees working.\n",
      "\n",
      "Here is the SQL query to get the count of active employees:\n",
      "```sql\n",
      "SELECT COUNT(e.emp_name) \n",
      "FROM employee e \n",
      "WHERE e.employment_status = 'active';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "schema_text = \"\"\"Critical HRMS Database Schema Relationships:\n",
    "        - `employee` holds core employee information.\n",
    "        * Use `emp_code` or `emp_name` to identify employees.\n",
    "        * Always filter with `employment_status = 'active'`.\n",
    "        * 'location' column is named as 'location_id_id'\n",
    "        * 'discipline' is as good as 'department'\n",
    "\n",
    "        - `attendance` logs daily attendance:\n",
    "        * `name` matches `grading_employee.emp_name`\n",
    "        * `empno` can be matched with `emp_code` or `user_id`\n",
    "        * `comment` values like 'Present', 'Half Day', etc. determine presence\n",
    "        * If `hours > 0`, it's considered as employee present\n",
    "\n",
    "        - `timetracking` logs task-level work:\n",
    "        * `user_id` links to `grading_employee.user_id`\n",
    "        * `emp_code` also maps to `grading_employee.emp_code`\n",
    "        * `date`, `time_spent`, and `status` fields track work effort\n",
    "        * Valid `status` values for inclusion: 'Submitted', 'Approved'\n",
    "\n",
    "        - `project` stores project metadata: `name`, `code`\n",
    "        - `teammember` connects employees to projects via foreign key to `auth_user.id`\n",
    "\n",
    "        - For location-based queries (e.g., \"employees by location\", \"headcount in each office\"), NEVER display raw location IDs.\n",
    "        - Instead, JOIN `employee e` with `location l` ON `e.location_id_id = l.id`\n",
    "        - SELECT `l.name AS location_name`, and GROUP BY `l.name`\n",
    "\n",
    "        ---------------------------------------------------------\n",
    "\n",
    "        Database Schema Relevant to Employee-Wise Engagement Reports:\n",
    "\n",
    "        Tables and Columns:\n",
    "\n",
    "        - `grading_attendance`:\n",
    "            * `name` — employee full name (matches `grading_employee.emp_name`)\n",
    "            * `attendance_date` — date of attendance (`YYYY-MM-DD`)\n",
    "            * `hours` — number of hours attended\n",
    "            * `comment` — attendance status (e.g., 'Present', 'Half Day', etc.)\n",
    "\n",
    "        - `grading_timetracking`:\n",
    "            * `user_id` — links to `grading_employee.user_id`\n",
    "            * `date` — date of time tracking (`YYYY-MM-DD`)\n",
    "            * `time_spent` — hours worked\n",
    "            * `status` — must be 'Submitted' or 'Approved'\n",
    "\n",
    "        - `grading_employee`:\n",
    "            * `user_id` — joins with `grading_timetracking.user_id`\n",
    "            * `emp_name` — employee name\n",
    "            * `emp_code` — employee code\n",
    "\n",
    "        Engagement Report Generation Logic (Natural Language Guidelines) -\n",
    "\n",
    "        For any query asking for employee-wise engagement/utilization reports (e.g., \"engagement report of Aman Chaturvedi\", \"utilization of emp_code 30311\", or \"employee productivity last month\"), generate SQL queries by following these steps:\n",
    "\n",
    "        1. **Calculate Total Attendance Hours:**\n",
    "        - Use a CTE named `total_attendance`.\n",
    "        - Select: `name`, `SUM(hours) AS total_hrs` from `grading_attendance`.\n",
    "        - Filter `comment` for valid presence indicators:\n",
    "            'Present', 'Half Day', 'Half Day Present - Half Day Absent', 'Present - Working On Weekend',\n",
    "            'Present - Working On Holiday', 'First Half Present - Second Half Leave', 'First Half Leave - Second Half Present'\n",
    "        - Apply date filter: `attendance_date BETWEEN '<start_date>' AND '<end_date>'`\n",
    "            - Convert natural language date inputs (e.g., \"May\", \"last month\") into valid date ranges.\n",
    "            - Dates must be formatted as `'YYYY-MM-DD'`.\n",
    "        - If employee name is provided, include:\n",
    "            `AND (name = \"<employee_name>\" OR \"<employee_name>\" IS NULL)`\n",
    "        - Group by `name`.\n",
    "\n",
    "        2. **Calculate Total Time Worked:**\n",
    "        - Use a second CTE named `total_timetracking`.\n",
    "        - Join `grading_employee AS e` with `grading_timetracking AS t` using:\n",
    "            `t.user_id = e.user_id`\n",
    "        - Select: `emp_name`, `emp_code`, `SUM(time_spent) AS total_time_spent`\n",
    "        - Filter: `t.status IN ('Submitted', 'Approved')`\n",
    "        - Apply date filter: `t.date BETWEEN '<start_date>' AND '<end_date>'`\n",
    "        - If employee code or name is provided, include:\n",
    "            `AND (emp_code = <employee_code> OR <employee_code> IS NULL OR emp_name = \"<employee_name>\")`\n",
    "        - Group by `emp_name`, `emp_code`\n",
    "\n",
    "        3. **Join and Compute Engagement Percentage:**\n",
    "        - Final SELECT should join:\n",
    "            `total_timetracking t JOIN total_attendance a ON t.emp_name = a.name`\n",
    "        - Select:\n",
    "            * `t.emp_name`\n",
    "            * `t.emp_code`\n",
    "            * `a.total_hrs`\n",
    "            * `t.total_time_spent`\n",
    "            * `ROUND((t.total_time_spent / a.total_hrs) * 100, 2) AS engagement_percent`\n",
    "\n",
    "        4. **Formatting and Output:**\n",
    "        - Dates must always be formatted as `'YYYY-MM-DD'`.\n",
    "        - Return a human-readable summary (not raw column names).\n",
    "        - Example output: “Aman Chaturvedi worked 92 hours out of 100 attended hours, resulting in 92.0% engagement.”\n",
    "\n",
    "        IMPORTANT: Always follow this structure for any employee-wise engagement query to ensure accuracy and consistency. \"\"\"\n",
    "\n",
    "\n",
    "conversation_context = \"Current conversation context here\"\n",
    "\n",
    "# \"How much man hour allotted for O5040\", \"who is batman?\", \"i want details of Aman Chaturvedi like their  employee code, email and graduation year\", \"how many total active employees are working\"  \"what is the status of EMPower OEDEC ERP project\" , \"What is the graduation year of Aman Chaturvedi?\"\n",
    "# \"I want timesheet report of Aman Chaturvedi from 1 may,2025 to 20 may,2025\", Generate employee-wise engagement report of employee code 30311 from 1 may to 30 may,2025\n",
    "# \"Show me pie chart of employee by location\",  \"Show me pie chart of employees by discipline\"  \n",
    "resolved_question = \"how many total active employees are working\"  \n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=f\"\"\"You are an advanced SQL assistant designed to interact with our HR database. Given an input question:\n",
    "                1. First validate if the question is relevant to HR data (employee, project, department, attendance,  utilization, etc.).\n",
    "                - If unrelated (e.g., \"Who is Batman?\"), return: \"This question is not related to the HR system. Please ask about employees, projects, or departments.\"\n",
    "                  \n",
    "                2. Create syntactically correct MySQL queries - no misplaced quotes or invalid characters or spelling error. \n",
    "                  \n",
    "                3. Return the answer in natural language format - NEVER return raw database values.\n",
    "                           \n",
    "                4. When writing SQL queries remember SQL FORMATTING RULES:\n",
    "                - Always use correct SQL syntax \n",
    "                - Column references must be properly quoted: `column_name` or table.column\n",
    "                - String literals must use single quotes: 'value'\n",
    "                - WHERE clauses must compare columns to values, not quotes: \n",
    "                - Always use table aliases (e.g. `grading_employee e`).\n",
    "                - Always qualify columns (e.g. `e.emp_name`).\n",
    "                - When filtering by dates, always use CAST('YYYY-MM-DD' AS DATE).\n",
    "                - For string matching, use LIKE with % wildcards.\n",
    "                - Do not include LIMIT clauses unless explicitly asked.\n",
    "                - Never use SELECT * — always specify required columns.\n",
    "                - Always join necessary tables using proper ON clauses, never assume implicit joins.\n",
    "                - Use LEFT JOIN only when needed, otherwise use INNER JOIN for performance and clarity.\n",
    "                  \n",
    "                5. For visualization requests (when user asks for charts/graphs), you MUST return structured JSON data in this format:\n",
    "                {{\n",
    "                \"type\": \"visualization_data\",\n",
    "                \"data\": {{\n",
    "                \"x_values\": [\"Category1\", \"Category2\", ...],\n",
    "                \"y_values\": [value1, value2, ...],\n",
    "                \"x_label\": \"X Axis Label\",\n",
    "                \"y_label\": \"Y Axis Label\",\n",
    "                \"title\": \"Chart Title\" }}\n",
    "                }}\n",
    "                NEVER return Python code for visualization requests - only return the structured data.\n",
    "                  \n",
    "                6. Special Instructions:\n",
    "                - Always return clean, human-readable results — no column names or raw SQL in final answers.\n",
    "                - When generating timesheet queries, always join `timetracking` with `employee` using `e.user_id = t.user_id`. Always include `t.date`, `t.time_spent`, `t.remarks`, and `t.status` in the SELECT clause unless a different column is explicitly requested.\n",
    "                  \n",
    "                7. Query Guidelines:\n",
    "                - DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "                - DO NOT query for sensitive information like passwords, credit card numbers, salary, ctc, monthly income, annual income etc.\n",
    "                - If the query requires a Pandas command, return a valid Pandas command, else just return the text.\n",
    "                - If the query requires a summary, return a text response.\n",
    "                - If the query asks for a chart or graph, always return the full Pandas DataFrame creation code along with appropriate chart instructions.\n",
    "\n",
    "\n",
    "                Database Schema Details:\n",
    "                {schema_text}\n",
    "\n",
    "                Current Conversation Context:\n",
    "                {conversation_context}\n",
    "\n",
    "          \n",
    "                Example Correct Queries:\n",
    "                ```sql\n",
    "                -- Counting active employees\n",
    "                SELECT COUNT(e.emp_name) \n",
    "                FROM employee e \n",
    "                WHERE e.employment_status = 'active'\n",
    "\n",
    "                -- Getting employee details\n",
    "                SELECT e.emp_name, e.date_of_joining\n",
    "                FROM employee e\n",
    "                WHERE e.department_id = 5 AND e.employment_status = 'active'      \n",
    "\n",
    "                -- allotted man hours\n",
    "                SELECT allotted_man_hours from project p WHERE p.code = 'O5040';                             \n",
    "\n",
    "                IMPORTANT RULES FOR RESPONSES:\n",
    "                - Always format dates properly (YYYY-MM-DD)\n",
    "                - Always include the employee name when available\n",
    "                - Never show raw database column names to users\n",
    "                - Convert technical terms into natural language and user-friendly descriptions\n",
    "                - Titles and field labels in final answers (like date of joining, employee name, total hours worked, etc.) MUST be wrapped in double asterisks — e.g., \"**Employee Name**\", \"**Date of Joining**\", \"**Engagement Percent**\"\n",
    "                - Example: Instead of \"date_of_joining: 2021-01-01\", respond with \"The **Date of Joining** is January 1, 2021\"\n",
    "                - Use only placeholders like <count>, <status>, etc. for dynamic answers. — never descriptive examples in brackets.\n",
    "                - Avoid hardcoded examples like \"[active/inactive]\" in final templates.\n",
    "\n",
    "                Example Good Responses:\n",
    "                - \"Aman Chaturvedi's date of joining is January 1, 2021.\"\n",
    "                - \"There are 5 active employees in the Engineering department.\"\n",
    "                - \"John Doe works in the Information Technology department.\"\n",
    "\n",
    "                Bad Responses:\n",
    "                - \"date_of_joining: 2021-01-01\"\n",
    "                - \"count: 5\"\n",
    "                - \"department: Information Technology\"\n",
    "                    \n",
    "                \"\"\"),\n",
    "    HumanMessage(content=f\"Answer this query: {resolved_question}. Use the appropriate response format (Pandas, table, text, or chart).\")\n",
    "]\n",
    "\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(\"\\n🤖  AI Response:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92ca7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_from_ai_response(ai_response_text: str, db_engine) -> str:\n",
    "    \"\"\"\n",
    "    Executes SQL extracted from the AI response and fills in the natural language template.\n",
    "    Returns human-readable text (always in sentence format) unless the response contains chart data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if response is a visualization JSON block\n",
    "    try:\n",
    "        parsed_json = json.loads(ai_response_text)\n",
    "        if isinstance(parsed_json, dict) and parsed_json.get(\"type\") == \"visualization_data\":\n",
    "            return parsed_json  # Return structured chart data as-is\n",
    "    except json.JSONDecodeError:\n",
    "        pass  # Continue if not a valid JSON\n",
    "\n",
    "    # Extract SQL query from AI response\n",
    "    sql_match = re.search(r\"```sql(.*?)```\", ai_response_text, re.DOTALL | re.IGNORECASE)\n",
    "    if not sql_match:\n",
    "        # Fallback if no SQL found – try to extract natural text\n",
    "        fallback_match = re.search(\n",
    "            r\"The final answer is:\\s*(?:\\\"([^\\\"]+)\\\"|'([^']+)'|([^\\n]+))\",\n",
    "            ai_response_text,\n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        if fallback_match:\n",
    "            return fallback_match.group(1) or fallback_match.group(2) or fallback_match.group(3)\n",
    "        return ai_response_text.strip()\n",
    "\n",
    "    sql_query = sql_match.group(1).strip()\n",
    "\n",
    "    try:\n",
    "        with db_engine.connect() as conn:\n",
    "            result = conn.execute(text(sql_query))\n",
    "            rows = result.fetchall()\n",
    "\n",
    "        if not rows:\n",
    "            return \"❌ No results found in the database.\"\n",
    "\n",
    "        # Try to extract the natural language template\n",
    "        nl_response_match = re.search(\n",
    "            r\"The final answer is:\\s*(?:\\\"([^\\\"]+)\\\"|'([^']+)'|([^\\n]+))\",\n",
    "            ai_response_text,\n",
    "            re.IGNORECASE | re.DOTALL\n",
    "        )\n",
    "\n",
    "        if nl_response_match:\n",
    "            response_template = nl_response_match.group(1) or nl_response_match.group(2) or nl_response_match.group(3)\n",
    "            response_template = response_template.strip()\n",
    "\n",
    "            # Use the first row of result for substitution\n",
    "            result_dict = dict(rows[0]._mapping)\n",
    "\n",
    "            for key, value in result_dict.items():\n",
    "                if hasattr(value, 'strftime'):\n",
    "                    value = value.strftime(\"%B %d, %Y\")\n",
    "                else:\n",
    "                    value = str(value)\n",
    "                response_template = re.sub(rf\"<{re.escape(key)}>\", value, response_template)\n",
    "                response_template = re.sub(rf\"\\[{re.escape(key)}\\]\", value, response_template)\n",
    "                response_template = re.sub(rf\"\\{{{re.escape(key)}\\}}\", value, response_template)\n",
    "\n",
    "            # Cleanup remaining placeholders\n",
    "            response_template = re.sub(r\"\\[.*?\\]\", \"\", response_template)\n",
    "            response_template = re.sub(r\"\\{.*?\\}\", \"\", response_template)\n",
    "            response_template = re.sub(r\"<.*?>\", \"\", response_template)\n",
    "\n",
    "            return response_template.strip()\n",
    "\n",
    "        else:\n",
    "            # No template found – build sentence from key-value pairs (natural language)\n",
    "            row = rows[0]._mapping\n",
    "            parts = []\n",
    "            for key, val in row.items():\n",
    "                label = key.replace('_', ' ').title()\n",
    "                if hasattr(val, 'strftime'):\n",
    "                    val = val.strftime(\"%B %d, %Y\")\n",
    "                parts.append(f\"The **{label}** is {val}\")\n",
    "            return \". \".join(parts) + \".\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error executing SQL query: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6301889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Answer: The **Count(E.Emp Name)** is 50.\n"
     ]
    }
   ],
   "source": [
    "final_answer = generate_answer_from_ai_response(response.content, engine)\n",
    "print(\"\\n✅ Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a3f74d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Answer: The **Graduation Year** is 2009.\n"
     ]
    }
   ],
   "source": [
    "final_answer = generate_answer_from_ai_response(response.content, engine)\n",
    "print(\"\\n✅ Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e9cbfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Answer: ✅ Final Answer:\n",
      "**Emp Code**: E1007 | **Email**: david.clark@company.com | **Graduation Year**: 2009\n"
     ]
    }
   ],
   "source": [
    "final_answer = generate_answer_from_ai_response(response.content, engine)\n",
    "print(\"\\n✅ Final Answer:\", final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bab737f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Final Answer: ✅ Final Answer:\n",
      "**Discipline**: Software Development | **Count**: 2\n",
      "**Discipline**: Digital Marketing | **Count**: 1\n",
      "**Discipline**: DevOps | **Count**: 3\n",
      "**Discipline**: Human Resources | **Count**: 1\n",
      "**Discipline**: Accounting | **Count**: 1\n",
      "**Discipline**: Frontend Development | **Count**: 2\n",
      "**Discipline**: System Administration | **Count**: 1\n",
      "**Discipline**: Content Marketing | **Count**: 1\n",
      "**Discipline**: Backend Development | **Count**: 2\n",
      "**Discipline**: Recruitment | **Count**: 1\n",
      "**Discipline**: Financial Analysis | **Count**: 1\n",
      "**Discipline**: Quality Assurance | **Count**: 1\n",
      "**Discipline**: Network Security | **Count**: 1\n",
      "**Discipline**: Social Media | **Count**: 1\n",
      "**Discipline**: Full Stack Development | **Count**: 1\n",
      "**Discipline**: Employee Relations | **Count**: 1\n",
      "**Discipline**: Audit | **Count**: 1\n",
      "**Discipline**: Mobile Development | **Count**: 1\n",
      "**Discipline**: Database Administration | **Count**: 1\n",
      "**Discipline**: SEO | **Count**: 1\n",
      "**Discipline**: Data Engineering | **Count**: 1\n",
      "**Discipline**: Training | **Count**: 1\n",
      "**Discipline**: Tax | **Count**: 1\n",
      "**Discipline**: UI/UX Design | **Count**: 1\n",
      "**Discipline**: Cloud Infrastructure | **Count**: 1\n",
      "**Discipline**: Email Marketing | **Count**: 1\n",
      "**Discipline**: Machine Learning | **Count**: 1\n",
      "**Discipline**: Compensation | **Count**: 1\n",
      "**Discipline**: Financial Planning | **Count**: 1\n",
      "**Discipline**: IT Support | **Count**: 2\n",
      "**Discipline**: Brand Management | **Count**: 1\n",
      "**Discipline**: Benefits | **Count**: 1\n",
      "**Discipline**: Investment | **Count**: 1\n",
      "**Discipline**: Cybersecurity | **Count**: 1\n",
      "**Discipline**: Market Research | **Count**: 1\n",
      "**Discipline**: QA Automation | **Count**: 1\n",
      "**Discipline**: IT Management | **Count**: 1\n",
      "**Discipline**: HRIS | **Count**: 1\n",
      "**Discipline**: Treasury | **Count**: 1\n",
      "**Discipline**: Data Science | **Count**: 1\n",
      "**Discipline**: Public Relations | **Count**: 1\n",
      "**Discipline**: Embedded Systems | **Count**: 1\n",
      "**Discipline**: Organizational Development | **Count**: 1\n",
      "**Discipline**: Risk Management | **Count**: 1\n"
     ]
    }
   ],
   "source": [
    "final_answer = generate_answer_from_ai_response(response.content, engine)\n",
    "print(\"\\n✅ Final Answer:\", final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
